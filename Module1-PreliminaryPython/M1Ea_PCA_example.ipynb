{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using Numpy for linear algebra and basic data analysis.**\n",
    "\n",
    "This notebook is meant as a companion to the notebook, \"M1E_Eigen_Values_Vectors_Decompositions_and_Transformations\".  In it we will load some data to create a Numpy array, and then we will use some linear algebra calculations to analyze some basic statistics for that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/QI2lab/2025-CBP-SummerSchool/blob/main/Module1-PreliminaryPython/M1Ea_PCA_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/QI2lab/2025-CBP-SummerSchool/blob/main/Module1-PreliminaryPython/M1Ea_PCA_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Installing and importing necessary packages.**\n",
    "\n",
    "Before we can do anything in this notebook, we need to make sure that we have the appropriate packages installed into our python environment.\n",
    "\n",
    "There are two ways to accomplish this:\n",
    "\n",
    "1) If we want to permanently add it to our environment (e.g., if it is something we will use many times), then we can use the **terminal** and run one of the commands (the choice of which command to use depends on how the developer wrote their codes):\n",
    "     * \"pip install [package name]\" - 'pip' installs python packages only and from source files.\n",
    "     * \"conda install [package name]\"  -- conda installs packages directly from binary files.  It can install many different types of functions (e.g., python, c++, java.).  Because it uses binary files, conda may be faster.\n",
    "\n",
    "2) We can accomplish the same functions within Jupyter by using **shell** commands.  By using the prefix, '!', we can run the following statements in a shell (as if it were a terminal).\n",
    "    *  \"!pip install [package name]\" \n",
    "    *  \"!conda install [package name]\"\n",
    "\n",
    "3) If we wish to istall it temporarilly for just the current session, we can use the magic commands within the notebook:\n",
    "    * \"%pip install [package name]\" - the so-called Jupyter magic command '%' at the beginning allows you to call special Jupyter commands.\n",
    "    * \"%conda install [package name]\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the scikit-learn library using the magic %pip% command\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import a bunch of pre-saved dataset from scikit-learn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example - Using PCA to Explore data sets to find interesting information.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at what is contained in the datasets we just loaded:\n",
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's load the specific data set for iris flowers\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Let's also get some information about that dataset\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some images of Irises.\n",
    "![image.png](./Module1-PreliminaryPython/iris.png)\n",
    "\n",
    "Image adapted from \"https://www.analyticsvidhya.com/blog/2022/06/iris-flowers-classification-using-machine-learning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data into a numpy array\n",
    "\n",
    "Now that we found a fun data set to explore, lets get it into a numpy array for subsequent processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The iris variable contains the following methods or data: {dir(iris)}')\n",
    "\n",
    "# If we want to know what type of data each of these methods or data are, we can use the type() function\n",
    "# on each attribute of the iris variable\n",
    "for x in dir(iris):\n",
    "    print(f'the type of {x} is {type(getattr(iris, x))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data itself\n",
    "irisData = iris.data\n",
    "\n",
    "# Now let's print the different methods and data that are contained in the irisData variable\n",
    "print(f'The irisData variable contains the following methods or data: {dir(irisData)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow, that's a lot of stuff! Let's look at the shape of the data\n",
    "print(f'The shape of the iris data is: {irisData.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the first 5 rows of data\n",
    "print(f'The first 5 rows of iris data are: {irisData[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the last 5 rows of data\n",
    "print(f'The last 5 rows of iris data are: {irisData[-5:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing some basic linear algebra to compute statistics from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compute the mean of each column using some linear algebra\n",
    "# Note that in python, matrix multiplication uses the @ symbol.\n",
    "meanIris = np.ones(irisData.shape[0]) @ irisData / irisData.shape[0]\n",
    "print(f'The mean of each column is: {meanIris}')\n",
    "\n",
    "# Lets compute the mean using the built-in numpy function\n",
    "meanIris = np.mean(irisData, axis=0)\n",
    "print(f'The mean of each column is: {meanIris}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the covariance matrix using some linear algebra\n",
    "# Note that in python, matrix multiplication uses the @ symbol.\n",
    "covIris = (irisData - meanIris).T @ (irisData - meanIris) / (irisData.shape[0]-1)\n",
    "print(f'The covariance matrix using algebra is: {covIris}')\n",
    "\n",
    "#Let's compute the covariance matrix using the built-in numpy function\n",
    "covIris = np.cov(irisData.T)\n",
    "print(f'The covariance matrix using builtin is: {covIris}')\n",
    "\n",
    "# Hmm.  these are close...\n",
    "# Based on what you learned in statistics class, can anyone tell me what the difference is between these two covariance matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.  these are close...\n",
    "Based on what you learned in statistics class, can anyone tell me what the difference is between these two covariance matrices and how I can get them to be the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making some plots to visualize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use matplotlib to make scatter plots of the data for all pairs of features\n",
    "# Here we will make a grid of 4 rows and 4 columns of plots showing all pairs of features\n",
    "# Note that the diagonal plots are histograms of each feature\n",
    "\n",
    "# First, we will set the size of the figure\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Now, we will use two for loops to loop over all pairs of features \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # Now we select the subplot we want to modify\n",
    "        plt.subplot(4, 4, i*4+j+1)\n",
    "        \n",
    "        if i == j:\n",
    "            # For the diagonals, we will plot a histogram of the data\n",
    "            plt.hist(irisData[:,i], bins=20)\n",
    "        else:\n",
    "            # For the off-diagonals, we will plot a scatter plot of the data\n",
    "            plt.scatter(irisData[:,j], irisData[:,i], c='black', s=2)\n",
    "        \n",
    "        if i==3:\n",
    "            # For the bottom row, we will label the x-axis\n",
    "            plt.xlabel(iris.feature_names[j])\n",
    "        if j==0:    \n",
    "            # For the left column, we will label the y-axis\n",
    "            plt.ylabel(iris.feature_names[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's see how data varies according to the species\n",
    "\n",
    "If our goal is to explore the differences between the four iris species, we should separate these out from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In machine learning, our goal is often to use the \"features\" to predict some \"target\" variable\n",
    "# In this case, the features are the measurements of the flowers, and the target is the species of the flower.\n",
    "# Let's look at the target variable:\n",
    "irisTarget = iris.target\n",
    "\n",
    "print(f'The type of irisTarget is {type(irisTarget)}')\n",
    "\n",
    "# Now let's print the different methods and data that are contained in the irisTarget variable\n",
    "print(f'The irisTarget variable contains the following methods or data: {dir(irisTarget)}')\n",
    "\n",
    "# Let's look at the shape of the data\n",
    "print(f'The shape of the iris target is: {irisTarget.shape}')\n",
    "\n",
    "# Let's look at the first 5 rows of data\n",
    "print(f'The first 5 rows of iris target are: {irisTarget[:5]}')\n",
    "\n",
    "# Lets look at the unique values of the target\n",
    "print(f'The unique values of the target are: {np.unique(irisTarget)}')\n",
    "\n",
    "# Let's look at the unique names of the target that correspond to these values\n",
    "print(f'The unique names of the target are: {iris.target_names}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets revisit the scatter plots, but this time color the points by the target\n",
    "\n",
    "# this time, let's put the figure generation in a function definition so that we can reuse it later\n",
    "def plotIrisData(irisData, irisTarget):\n",
    "\n",
    "    # First, we will set the size of the figure\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Now, we will use two for loops to loop over all pairs of features\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            # Now we select the subplot we want to modify\n",
    "            plt.subplot(4, 4, i*4+j+1)\n",
    "        \n",
    "            if i == j:\n",
    "                # For the diagonals, we will plot a histogram of the data\n",
    "                plt.hist(irisData[:,i], bins=20)\n",
    "            else:\n",
    "                # For the off-diagonals, we will plot a scatter plot of the data\n",
    "                # THESE ARE THE ONLY LINEs THAT CHANGED FROM ABOVE\n",
    "                for iFlower in range(3):\n",
    "                    plt.scatter(irisData[irisTarget==iFlower,j], irisData[irisTarget==iFlower,i], s=2)\n",
    "\n",
    "            if i==3:\n",
    "                # For the bottom row, we will label the x-axis\n",
    "                plt.xlabel(iris.feature_names[j])\n",
    "            if j==0:    \n",
    "                # For the left column, we will label the y-axis\n",
    "                plt.ylabel(iris.feature_names[j])\n",
    "\n",
    "    # Let's add a legend to the top right of the figure\n",
    "    # first, we will get the current axes corresponding to the top right plot\n",
    "    ax = plt.subplot(4,4,4)\n",
    "    # then we will add a legend to that plot\n",
    "    plt.legend(iris.target_names, loc='upper right')\n",
    "\n",
    "    # Finally, we will add some space between the plots so that the labels don't overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Now, let's call the function we just defined\n",
    "plotIrisData(irisData, irisTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition and Principal Component Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data\n",
    "\n",
    "The process of normalization is to transform the data so that it has a mean of zero and a variance of one. \n",
    "\n",
    "To achieve this, we subtract the mean for each feature and divide by the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the means and variances for our data, let's normalize it:\n",
    "# First, we will subtract the mean from each column\n",
    "irisDataNorm = irisData - meanIris\n",
    "# Next, we will divide each column (axis = 0) by the standard deviation\n",
    "irisDataNorm = irisDataNorm / np.std(irisDataNorm, axis=0)\n",
    "\n",
    "# Let's plot the normalized data using the same code as above:\n",
    "plotIrisData(irisDataNorm, irisTarget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Singular Value Decomposition\n",
    "Now that we have normalized data, we can apply SVD to compute the principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the SVD of the normalized data\n",
    "U, S, V = np.linalg.svd(irisDataNorm, full_matrices=False)\n",
    "# Here we use the full_matrices=False option to tell the function to only return the first 4 columns of U and the first 4 rows of V (the first 4 singular values)\n",
    "\n",
    "# Let's look at the shape of the matrices\n",
    "print(f'The shape of irisDataNorm is: {irisDataNorm.shape}')\n",
    "print(f'The shape of U is: {U.shape}')\n",
    "print(f'The shape of S is: {S.shape}')\n",
    "print(f'The shape of V is: {V.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the singular values\n",
    "print(f'The singular values are: {S}')\n",
    "\n",
    "# Let's also see how much of the variance is explained by each singular value\n",
    "varExplained = S**2 / np.sum(S**2)\n",
    "print(f'The variance explained by each singular value is: {varExplained}')\n",
    "\n",
    "print(f'The variance explained by the first two singular values is: {np.sum(varExplained[:2])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Interpretation of the right Singular Vector, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the first two rows of V, which correspond to the first two principal components\n",
    "print(f'The first rows of V are: {V[:2,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what do the numbers in V actually mean? \n",
    "\n",
    "# Let's replot our original data.\n",
    "plotIrisData(irisDataNorm, irisTarget)\n",
    "\n",
    "# Now let's add vectors corresponding to the first two ROWS of V to this plot.\n",
    "\n",
    "# First, we will get the current axes corresponding to the top right plot\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if i!=j:\n",
    "            ax = plt.subplot(4,4,i*4+j+1)\n",
    "            plt.quiver(np.zeros(2), np.zeros(2), V[:2,i], V[:2,j], color=['r','b'], scale=3)        \n",
    "\n",
    "# This image now shows the directions of the first two principal components in the original data space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix V allows us to transform our data into the principal component space.\n",
    "# Let's compute the principal component space representation of our data, using the first two principal components\n",
    "irisDataPC = irisDataNorm @ V[:2,:].T\n",
    "\n",
    "# Let's look at the shape of the data\n",
    "print(f'The shape of the iris data is: {irisData.shape}')\n",
    "print(f'The shape of the iris data in PC space is: {irisDataPC.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot the data in PC space\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(3):\n",
    "    plt.scatter(irisDataPC[irisTarget==i,0], irisDataPC[irisTarget==i,1], s=4)\n",
    "\n",
    "plt.legend(iris.target_names, loc='upper right')\n",
    "plt.xlabel('Principle Component 1 ')\n",
    "plt.ylabel('Principle Component 2 ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between covariance matrix and singular value decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our nurmalized data (zero mean and unit variance for all columns), D, we computed the SVD:\n",
    "#      D = U @ S @ V.T\n",
    "# We also computed the covariance matrix:\n",
    "#     C = D.T @ D / (N-1)   (where N is the number of samples)\n",
    "# We can show that the covariance matrix is related to the SVD by:\n",
    "#     C = (V @ S @ U^T) @ ( U @ S @ V^T ) / (N-1) = (V @ S**2 @ V.T) / (N-1)\n",
    "# Because C is positive definite, we can also diagonalize it using the eigendecomposition:\n",
    "#     C = E * L * E.T\n",
    "# where E is the matrix of eigenvectors, and L is the diagonal matrix of the eigenvalues of C\n",
    "# We can show that the eigenvectors of C are related to the SVD by:\n",
    "#     E = V\n",
    "# and the eigenvalues of C are related to the SVD by:\n",
    "#     L = S**2 / (N-1)\n",
    "\n",
    "# Let's check this for our data:\n",
    "\n",
    "# First, let's compute the covariance matrix of our normalized data\n",
    "covNormIris = irisDataNorm.T @ irisDataNorm / irisDataNorm.shape[0]\n",
    "# Next, let's print the eigenvalues and eigenvectors of the covariance matrix\n",
    "print(f'The eigenvalues of the  iris covariance matrix are {np.linalg.eig(covNormIris)[0]}')\n",
    "print(f'The eigenvalues vectors of the  iris covariance matrix are {np.linalg.eig(covNormIris)[1]}')\n",
    "\n",
    "# Now, let's print the singular values and vectors of the normalized data\n",
    "print(f'The S^2/N for our SVD analysis of the data are {S**2/irisDataNorm.shape[0]}')\n",
    "print(f'The values of V are {V}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets vidualize how the SVD reduction looks in the original space\n",
    "# First, we will plot the original data.\n",
    "plotIrisData(irisDataNorm, irisTarget)\n",
    "\n",
    "components = [0]\n",
    "# Now lets compute the estimate of this data using the first two principal components\n",
    "irisDataRed = U[:,components] @ np.diag(S[components]) @ V[components,:]\n",
    "\n",
    "# now lets add the estimate to the plot and use lines to connect the points.\n",
    "# with the color of the lines matching the color of the points\n",
    "# between the original data and the estimate\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if i==j:\n",
    "            # add the histogram for the reduced data\n",
    "            ax = plt.subplot(4,4,i*4+j+1)\n",
    "            plt.hist(irisDataRed[:,i], bins=20)\n",
    "        else:\n",
    "            ax = plt.subplot(4,4,i*4+j+1)\n",
    "            for iFlower in range(3):\n",
    "                # plot the reduced data using x's\n",
    "                plt.scatter(irisDataRed[irisTarget==iFlower,j], irisDataRed[irisTarget==iFlower,i], s=4, marker='x')\n",
    "                # plot the original data using circles\n",
    "                plt.scatter(irisDataNorm[irisTarget==iFlower,j], irisDataNorm[irisTarget==iFlower,i], s=4)\n",
    "                # plot lines connecting the original and reduced data\n",
    "                plt.plot([irisDataNorm[irisTarget==iFlower,j], irisDataRed[irisTarget==iFlower,j]], \\\n",
    "                        [irisDataNorm[irisTarget==iFlower,i], irisDataRed[irisTarget==iFlower,i]], alpha=0.1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIOM480A5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

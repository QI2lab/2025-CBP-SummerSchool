{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZRaHmdi80X"
      },
      "source": [
        "<html>\n",
        "    <summary></summary>\n",
        "         <div> <p></p> </div>\n",
        "         <div style=\"font-size: 20px; width: 800px;\">\n",
        "              <h1>\n",
        "               <left>Stochastic modeling of bacteria growth</left>\n",
        "              </h1>\n",
        "              <p><left>============================================================================</left> </p>\n",
        "<pre>Course: ASU CBP Summer School 2025\n",
        "Instructor: Dr. Douglas Shepherd\n",
        "Contact Info: douglas.shepherd@asu.edu\n",
        "Authors: Dr. Douglas Shepherd\n",
        "</pre>\n",
        "         </div>\n",
        "    </p>\n",
        "\n",
        "</html>\n",
        "\n",
        "<details>\n",
        "  <summary>Copyright info</summary>\n",
        "\n",
        "```\n",
        "Copyright 2025 Douglas Shepherd\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "```\n",
        "<details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/QI2lab/2025-CBP-SummerSchool/blob/main/Module4-BacteriaGrowth/M4C_Stochastic_Growth_Rate.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/QI2lab/2025-CBP-SummerSchool/blob/main/Module4-BacteriaGrowth/M4C_Stochastic_Growth_Rate.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DJG8AGu9mVt",
        "outputId": "d0a4ba77-441d-4dc6-e8dc-162eb13363d0"
      },
      "outputs": [],
      "source": [
        "!pip install pymc arviz numcodecs imagecodecs tiffile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agln4lgojHbn"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/QI2lab/2025-CBP-SummerSchool/blob/main/Module4-BacteriaGrowth/M4C_Stochastic_Growth_Rate.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/QI2lab/2025-CBP-SummerSchool/blob/main/Module4-BacteriaGrowth/M4C_Stochastic_Growth_Rate.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlwOmcnbjL84"
      },
      "source": [
        "# Learning Objectives\n",
        "In this lesson, we are going to use an advancedd method, called Markov Chain Monte Carlo (MCMC) to analyze and fit experimental data of bacteria dividing to determine their growth rate. To fully understand this material, you will need to go over the optional material in Module 5.\n",
        "\n",
        "After completing this lesson, you should be able to:\n",
        "* Fit the distribution of cell division times using an ODE model, MCMC sampling, and the experimental data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwZ7urmBjjj4"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwT9XdyP9vy-"
      },
      "outputs": [],
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "import tifffile\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "import xarray as xr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r09SUJxg90ay"
      },
      "source": [
        "### Setup HMC for exponential growth\n",
        "\n",
        "We are going to use [PyMC](https://www.pymc.io/welcome.html), a probabilistic programming library, to fit the data in this example.\n",
        "\n",
        "At a high-level, the idea is to try many different random parameter combinations and see how well the model fits for each combination. By adding up all of the times the solver found a given growth rate value fit the model \"well\", we can then make a distribution of the most likely growth rates given the model and data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqILZzer93jl"
      },
      "outputs": [],
      "source": [
        "def exponential_solution(times: np.ndarray, k1: float, N0: float) -> np.ndarray:\n",
        "  \"\"\"Analytic solution N(t) = N0 * exp(k1 * t).\"\"\"\n",
        "  return N0 * np.exp(k1 * times)\n",
        "\n",
        "def build_model_counts_neg_bin(times: np.ndarray, counts: np.ndarray) -> pm.Model:\n",
        "  \"\"\"PyMC model: counts ~ NegBin(mu=N0*exp(k1*t), alpha).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  times\n",
        "      1D array of timepoints (shape (T,)).\n",
        "  counts\n",
        "      1D or 2D array of integer counts. If 2D (R, T), each row is a replicate.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  model\n",
        "      A compiled PyMC model ready for sampling.\n",
        "  \"\"\"\n",
        "  times = np.asarray(times, dtype=float)\n",
        "  counts = np.asarray(counts)\n",
        "\n",
        "  # If replicates are provided as (R, T), broadcast mu over the replicate axis\n",
        "  if counts.ndim == 2:\n",
        "    R, T = counts.shape\n",
        "    assert T == times.size\n",
        "  else:\n",
        "    T = counts.size\n",
        "    assert T == times.size\n",
        "    counts = counts[None, :]       # (1, T) for uniform handling\n",
        "    R = 1\n",
        "\n",
        "  with pm.Model() as model:\n",
        "    # Weakly-informative priors (tune these if you have prior knowledge)\n",
        "    k1 = pm.LogNormal(\"k1\", mu=0.05, sigma=.5)        # k1 > 0\n",
        "    N0 = pm.LogNormal(\"N0\", mu=np.log(max(counts.mean(), 1.0)), sigma=2.0)\n",
        "\n",
        "    # Overdispersion (alpha -> 0 becomes Poisson-like)\n",
        "    alpha = pm.HalfNormal(\"alpha\", sigma=2.0)\n",
        "\n",
        "    mu_t = exponential_solution(times, k1, N0)        # shape (T,)\n",
        "    mu = pm.Deterministic(\"mu\", mu_t)                 # keep for diagnostics\n",
        "\n",
        "    # Likelihood: broadcast across replicates\n",
        "    pm.NegativeBinomial(\n",
        "        \"obs\", mu=mu[None, :], alpha=alpha, observed=counts\n",
        "    )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMfgSH70-AXI"
      },
      "source": [
        "### Load and read in experimental data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "AGvXN1er-IGz",
        "outputId": "3f2b6e86-d4c1-4591-aa8c-bc35b22cf926"
      },
      "outputs": [],
      "source": [
        "# Download data\n",
        "!pip install -q gdown\n",
        "import gdown\n",
        "\n",
        "# download the .zip containing the image data\n",
        "file_id = \"1nxY9-jEGmrH8elRdiMENFhBb64mMYl8q\"\n",
        "out = \"/content/cbpSS2025.zip\"\n",
        "gdown.download(id = file_id, output=out,quiet=False)\n",
        "\n",
        "# unzip data\n",
        "!unzip -q /content/cbpSS2025.zip -d /content/cbpSS2025/\n",
        "\n",
        "file_id = \"1nW_-ouf_6THFhuoXNEL5GkcB3twmYQNS\"\n",
        "out = \"/content/cbpSS2025/tracking_result.txt\"\n",
        "\n",
        "# Using the ID avoids any Drive viewer HTML\n",
        "gdown.download(id=file_id, output=out, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riTWvNOk-LAn"
      },
      "outputs": [],
      "source": [
        "# load segmented phase-contrast image data\n",
        "mask_files = sorted(Path(\"/content/cbpSS2025/masks/\").glob(\"*.tif*\"))\n",
        "mask_data = []\n",
        "for mask_file in mask_files:\n",
        "  mask_data.append(tifffile.imread(mask_file))\n",
        "mask_data = np.asarray(mask_data,dtype=np.uint16)[0:20,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFvjPZm1BzDo"
      },
      "outputs": [],
      "source": [
        "# load segmented and tracked phase-contrast image data\n",
        "tracked_files = sorted(Path(\"/content/cbpSS2025/result/\").glob(\"*.tif*\"))\n",
        "tracked_data = []\n",
        "for tracked_file in tracked_files:\n",
        "  tracked_data.append(tifffile.imread(tracked_file))\n",
        "tracked_data = np.asarray(tracked_data,dtype=np.uint16)[0:20,:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcZ84dFS-X3D"
      },
      "source": [
        "### Process segmented data to get number of bacteria per timepoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shi4bUQS-VxR"
      },
      "outputs": [],
      "source": [
        "bacteria_counts = np.max(mask_data,axis=(1,2))\n",
        "times = np.linspace(0,mask_data.shape[0],mask_data.shape[0]) * 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34r6FhiuB-Fo"
      },
      "source": [
        "### Process tracked data to get distribution of division times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKvL4KeFCCCm"
      },
      "outputs": [],
      "source": [
        "def division_time_histogram(\n",
        "    filename: str | Path,\n",
        "    timestep_min: float,\n",
        "    bins: int | str = \"auto\",\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"Compute a histogram of cell division times from a TrackAstra result file.\n",
        "\n",
        "  The input file must have 4 whitespace-separated integer columns per line:\n",
        "  L B E P\n",
        "    - L: track label (positive int)\n",
        "    - B: birth frame index (0-based)\n",
        "    - E: end frame index (0-based)\n",
        "    - P: parent label (0 if no parent)\n",
        "\n",
        "  A division event is defined as any parent label with >= 2 daughters.\n",
        "  The division frame is the mode (most frequent) of the daughters' birth\n",
        "  frames for that parent; ties resolve to the smallest such frame. Division\n",
        "  time (minutes) = (division_frame - parent_birth_frame) * timestep_min.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename\n",
        "      Path to the TrackAstra track file.\n",
        "  timestep_min\n",
        "      Minutes per frame (e.g., 5.0 for 5-minute intervals).\n",
        "  bins\n",
        "      Binning specification passed to ``np.histogram`` (default \"auto\").\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  counts : np.ndarray, shape (n_bins,)\n",
        "      Histogram counts per bin.\n",
        "  bin_centers : np.ndarray, shape (n_bins,)\n",
        "      Bin center locations (minutes), suitable for plotting.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  - Lines with fewer than two daughters for a parent are ignored.\n",
        "  - Events with non-positive elapsed frames are ignored.\n",
        "\n",
        "  Examples\n",
        "  --------\n",
        "  >>> counts, centers = division_time_histogram(\"res_track.txt\", 5.0)\n",
        "  >>> import matplotlib.pyplot as plt\n",
        "  >>> plt.plot(centers, counts, marker=\"o\")\n",
        "  >>> plt.xlabel(\"Division time (min)\")\n",
        "  >>> plt.ylabel(\"Count\")\n",
        "  >>> plt.show()\n",
        "  \"\"\"\n",
        "  arr = np.loadtxt(filename, dtype=np.int64)\n",
        "  if arr.ndim != 2 or arr.shape[1] < 4:\n",
        "      raise ValueError(\"Track file must have 4 columns: L B E P.\")\n",
        "\n",
        "  labels = arr[:, 0]\n",
        "  births = arr[:, 1]\n",
        "  parents = arr[:, 3]\n",
        "\n",
        "  # Map: label -> birth frame\n",
        "  label_to_birth: dict[int, int] = {}\n",
        "  for lbl, b in zip(labels, births):\n",
        "      # If duplicated labels appear, keep the first B seen.\n",
        "      label_to_birth.setdefault(int(lbl), int(b))\n",
        "\n",
        "  # Map: parent_label -> list of row indices of daughters\n",
        "  daughters_by_parent: dict[int, list[int]] = {}\n",
        "  for idx, p in enumerate(parents):\n",
        "      if p != 0:\n",
        "          daughters_by_parent.setdefault(int(p), []).append(idx)\n",
        "\n",
        "  division_times_min: list[float] = []\n",
        "\n",
        "  for parent_lbl, idxs in daughters_by_parent.items():\n",
        "      if len(idxs) < 2:\n",
        "          continue\n",
        "      # Parent must exist in table (to have birth time)\n",
        "      parent_birth = label_to_birth.get(parent_lbl)\n",
        "      if parent_birth is None:\n",
        "          continue\n",
        "\n",
        "      daughter_birth_frames = births[idxs].astype(int)\n",
        "      # Mode of daughters' birth frames (tie -> smallest)\n",
        "      vals, cnts = np.unique(daughter_birth_frames, return_counts=True)\n",
        "      division_frame = int(vals[np.argmax(cnts)])\n",
        "      frames_elapsed = int(division_frame - parent_birth)\n",
        "      if frames_elapsed <= 0:\n",
        "          continue\n",
        "\n",
        "      division_times_min.append(frames_elapsed * float(timestep_min))\n",
        "\n",
        "  times = np.asarray(division_times_min, dtype=float)\n",
        "  if times.size == 0:\n",
        "      # No valid events\n",
        "      return np.array([], dtype=float), np.array([], dtype=float)\n",
        "\n",
        "  counts, bin_edges = np.histogram(times, bins=bins)\n",
        "  bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n",
        "  return counts.astype(float, copy=False), bin_centers\n",
        "\n",
        "division_times, bin_center = division_time_histogram(\n",
        "  filename = Path(\"/content/cbpSS2025/tracking_result.txt\"),\n",
        "  timestep_min = 5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps9xgSYY-qLh"
      },
      "source": [
        "### Run the MCMC sampling using PyMC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "698e8706d6a64e6b92b35ca7a0cc2642",
            "45d9112496b74f76ae0ce3a225b0ae5f",
            "f1f74da7bce04cca9c5b63f9fa74ba38",
            "e44fa7896af8492d9670c256c2cc4d89"
          ]
        },
        "id": "h02oWT2s99tL",
        "outputId": "f2f24e6d-94d8-486c-e24d-aaf327df6a67"
      },
      "outputs": [],
      "source": [
        "with build_model_counts_neg_bin(times, bacteria_counts) as m:\n",
        "    idata = pm.sample(10000, tune=2000, chains=4, target_accept=0.9)\n",
        "    ppc = pm.sample_posterior_predictive(idata)\n",
        "    dt = np.log(2.0) / idata.posterior[\"k1\"]\n",
        "    idata.posterior = idata.posterior.assign(doubling_time=dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy_fzdCefJmP"
      },
      "source": [
        "### Plot distribution of sampled division times versus actual division times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPH52xvTfVnU"
      },
      "outputs": [],
      "source": [
        "def _approx_edges_from_centers(centers: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Compute bin edges from bin centers (works for uniform or varying widths).\"\"\"\n",
        "    centers = np.asarray(centers, dtype=float)\n",
        "    if centers.size == 0:\n",
        "        raise ValueError(\"bin_centers must be non-empty.\")\n",
        "    if centers.size == 1:\n",
        "        step = 1.0\n",
        "        return np.array([centers[0] - step/2, centers[0] + step/2])\n",
        "    edges = np.empty(centers.size + 1, dtype=float)\n",
        "    edges[1:-1] = 0.5 * (centers[:-1] + centers[1:])\n",
        "    edges[0] = centers[0] - (centers[1] - centers[0]) / 2.0\n",
        "    edges[-1] = centers[-1] + (centers[-1] - centers[-2]) / 2.0\n",
        "    return edges\n",
        "\n",
        "def _get_dt_samples(idata: az.InferenceData, prefer_existing: bool = True) -> np.ndarray:\n",
        "    \"\"\"Extract doubling-time samples from idata (uses 'doubling_time' if present; else ln2/k1).\"\"\"\n",
        "    post: xr.Dataset = idata.posterior  # (chain, draw, ...)\n",
        "    if prefer_existing and \"doubling_time\" in post:\n",
        "        dt = post[\"doubling_time\"].values\n",
        "    else:\n",
        "        if \"k1\" not in post:\n",
        "            raise KeyError(\"Neither 'doubling_time' nor 'k1' found in idata.posterior.\")\n",
        "        k1 = post[\"k1\"].values\n",
        "        dt = np.log(2.0) / k1\n",
        "    dt = np.asarray(dt, dtype=float).reshape(-1)  # flatten (chains * draws,)\n",
        "    dt = dt[np.isfinite(dt) & (dt > 0)]\n",
        "    if dt.size == 0:\n",
        "        raise ValueError(\"No valid (positive, finite) doubling-time samples found.\")\n",
        "    return dt\n",
        "\n",
        "def _hist_median(counts: np.ndarray, edges: np.ndarray) -> float:\n",
        "    \"\"\"Median of a 1D histogram using linear interpolation inside the median bin.\"\"\"\n",
        "    counts = np.asarray(counts, dtype=float)\n",
        "    edges = np.asarray(edges, dtype=float)\n",
        "    total = counts.sum()\n",
        "    if total <= 0:\n",
        "        return np.nan\n",
        "    csum = np.cumsum(counts)\n",
        "    half = 0.5 * total\n",
        "    # First bin where cumulative >= half\n",
        "    idx = int(np.searchsorted(csum, half, side=\"left\"))\n",
        "    idx = np.clip(idx, 0, counts.size - 1)\n",
        "    c_before = 0.0 if idx == 0 else csum[idx - 1]\n",
        "    in_bin = counts[idx]\n",
        "    lo, hi = edges[idx], edges[idx + 1]\n",
        "    if in_bin <= 0 or not np.isfinite(in_bin):\n",
        "        # Fallback: center of the bin if it’s empty or weird\n",
        "        return 0.5 * (lo + hi)\n",
        "    frac = (half - c_before) / in_bin\n",
        "    frac = np.clip(frac, 0.0, 1.0)\n",
        "    return lo + frac * (hi - lo)\n",
        "\n",
        "def plot_true_vs_posterior_doubling_time(\n",
        "    counts: np.ndarray,\n",
        "    bin_centers: np.ndarray,\n",
        "    idata: az.InferenceData,\n",
        "    *,\n",
        "    show_kde: bool = True,\n",
        "    show_ppc: bool = True,\n",
        "    hdi_prob: float = 0.95,\n",
        ") -> None:\n",
        "    \"\"\"Overlay the empirical division-time histogram with posterior for doubling time.\n",
        "\n",
        "    - Bars: empirical histogram as a *density* (area=1)\n",
        "    - Line: KDE of posterior doubling-time samples (optional, show_kde=True)\n",
        "    - Markers: posterior-predictive expected *counts per bin* (optional, show_ppc=True)\n",
        "    - Vertical dotted line: empirical median division time\n",
        "    \"\"\"\n",
        "    counts = np.asarray(counts, dtype=float)\n",
        "    centers = np.asarray(bin_centers, dtype=float)\n",
        "    assert counts.shape == centers.shape, \"counts and bin_centers must align\"\n",
        "\n",
        "    # Reconstruct edges and widths for density conversion\n",
        "    edges = _approx_edges_from_centers(centers)\n",
        "    widths = np.diff(edges)\n",
        "    total = counts.sum()\n",
        "    density = counts / (total * widths) if total > 0 else np.zeros_like(counts)\n",
        "\n",
        "    # Empirical median (minutes) from the histogram\n",
        "    emp_median = _hist_median(counts, edges)\n",
        "\n",
        "    # Posterior samples of doubling time\n",
        "    dt_samples = _get_dt_samples(idata)\n",
        "    q_lo, q_hi = np.quantile(dt_samples, [(1 - hdi_prob) / 2, 1 - (1 - hdi_prob) / 2])\n",
        "    dt_med = np.median(dt_samples)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "    # 1) Empirical histogram as density bars\n",
        "    ax.bar(centers, density, width=widths, align=\"center\", alpha=0.4, label=\"Empirical density\")\n",
        "\n",
        "    # 1b) Empirical median line\n",
        "    if np.isfinite(emp_median):\n",
        "        ax.axvline(emp_median, linestyle=\":\", linewidth=1.5,\n",
        "                   label=f\"Empirical median = {emp_median:.2f}\")\n",
        "\n",
        "    # 2) KDE of posterior doubling time (density)\n",
        "    if show_kde:\n",
        "        kde = gaussian_kde(dt_samples)\n",
        "        # x-grid spanning both data & posterior\n",
        "        x_min = min(edges[0], np.quantile(dt_samples, 0.001))\n",
        "        x_max = max(edges[-1], np.quantile(dt_samples, 0.999))\n",
        "        x = np.linspace(x_min, x_max, 512)\n",
        "        y = kde(x)\n",
        "        ax.plot(x, y, label=\"Posterior KDE of doubling time\")\n",
        "        # Shade HDI and mark posterior median\n",
        "        ax.axvspan(q_lo, q_hi, alpha=0.1, label=f\"{int(hdi_prob*100)}% HDI (doubling time)\")\n",
        "        ax.axvline(dt_med, linestyle=\"--\", linewidth=1.2, label=f\"Posterior median = {dt_med:.2f}\")\n",
        "\n",
        "    # 3) Posterior-predictive counts-in-bins from posterior dt samples\n",
        "    if show_ppc:\n",
        "        # Probability that dt falls in each bin ≈ fraction of samples in that bin\n",
        "        bin_idx = np.digitize(dt_samples, edges) - 1  # 0..B-1\n",
        "        bin_idx = bin_idx[(bin_idx >= 0) & (bin_idx < counts.size)]\n",
        "        freq = np.bincount(bin_idx, minlength=counts.size).astype(float)\n",
        "        prob_in_bin = freq / freq.sum() if freq.sum() > 0 else np.zeros_like(freq)\n",
        "        expected_counts = total * prob_in_bin\n",
        "        # Plot as markers connected at bin centers (convert to density to match bars)\n",
        "        ax.plot(centers, expected_counts / (total * widths), marker=\"o\",\n",
        "                linestyle=\"-\", label=\"Posterior-predictive density (binned)\")\n",
        "\n",
        "    ax.set_xlabel(\"Division time / Doubling time (minutes)\")\n",
        "    ax.set_ylabel(\"Density\")\n",
        "    ax.set_title(\"Empirical distribution vs posterior for doubling time\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "xEK9KHWXfWQI",
        "outputId": "10109bfc-9523-42b2-950d-17f77b75fe6e"
      },
      "outputs": [],
      "source": [
        "plot_true_vs_posterior_doubling_time(\n",
        "    counts=division_times,\n",
        "    bin_centers=bin_center,\n",
        "    idata=idata,\n",
        "    show_kde=True,\n",
        "    show_ppc=True,\n",
        "    hdi_prob=0.95,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jd9lGGqssQE"
      },
      "source": [
        "This worked out pretty well!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45d9112496b74f76ae0ce3a225b0ae5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698e8706d6a64e6b92b35ca7a0cc2642": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_45d9112496b74f76ae0ce3a225b0ae5f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                  </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   12000   0             0.42        5            880.69 draws/s   0:00:13   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   12000   0             0.40        7            420.41 draws/s   0:00:28   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   12000   0             0.35        15           277.76 draws/s   0:00:43   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   12000   0             0.46        7            211.96 draws/s   0:00:56   0:00:00    \n                                                                                                                   \n</pre>\n",
                  "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                 \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   12000   0             0.42        5            880.69 draws/s   0:00:13   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   12000   0             0.40        7            420.41 draws/s   0:00:28   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   12000   0             0.35        15           277.76 draws/s   0:00:43   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   12000   0             0.46        7            211.96 draws/s   0:00:56   0:00:00    \n                                                                                                                   \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "e44fa7896af8492d9670c256c2cc4d89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f74da7bce04cca9c5b63f9fa74ba38": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e44fa7896af8492d9670c256c2cc4d89",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling ... <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> 0:00:00 / 0:00:11\n</pre>\n",
                  "text/plain": "Sampling ... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m 0:00:00 / 0:00:11\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
